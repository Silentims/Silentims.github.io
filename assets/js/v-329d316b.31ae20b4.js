"use strict";(self.webpackChunkswbook=self.webpackChunkswbook||[]).push([[743],{3018:(e,r,a)=>{a.r(r),a.d(r,{data:()=>t});const t={key:"v-329d316b",path:"/interview/interview-all.html",title:"Java 集合",lang:"zh-CN",frontmatter:{},excerpt:"",headers:[{level:2,title:"参考",slug:"参考",children:[]},{level:2,title:"面试题",slug:"面试题",children:[]},{level:2,title:"参考",slug:"参考-1",children:[]},{level:2,title:"面试题",slug:"面试题-1",children:[]},{level:2,title:"面试题",slug:"面试题-2",children:[]},{level:2,title:"数据结构",slug:"数据结构",children:[]},{level:2,title:"面试题",slug:"面试题-3",children:[]},{level:2,title:"面试题",slug:"面试题-4",children:[]},{level:2,title:"面试题",slug:"面试题-5",children:[]}],filePathRelative:"interview/interview-all.md"}},5331:(e,r,a)=>{a.r(r),a.d(r,{default:()=>I});var t=a(6252);const n=(0,t.uE)('<h1 id="java-集合" tabindex="-1"><a class="header-anchor" href="#java-集合" aria-hidden="true">#</a> Java 集合</h1><h1 id="java-线程池" tabindex="-1"><a class="header-anchor" href="#java-线程池" aria-hidden="true">#</a> Java 线程池</h1><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2>',3),i={href:"https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485808&idx=1&sn=1013253533d73450cef673aee13267ab&chksm=cea246bbf9d5cfad1c21316340a0ef1609a7457fea4113a1f8d69e8c91e7d9cd6285f5ee1490&token=510053261&lang=zh_CN&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},p=(0,t.Uk)("新手也能看懂的线程池学习总结"),o=(0,t.Uk)("——JavaGuide"),l={href:"https://www.jianshu.com/p/78267c8405f4",target:"_blank",rel:"noopener noreferrer"},s=(0,t.Uk)("线程池的核心线程数如何确定"),d=(0,t.Uk)("——简书"),h=(0,t.uE)('<h2 id="面试题" tabindex="-1"><a class="header-anchor" href="#面试题" aria-hidden="true">#</a> 面试题</h2><p><strong>线程池的大致实现和机制是怎么样的？</strong></p><p>线程池的实现主要是由Executor框架实现的，大致可以分为任务（Runable/Callable）、任务的执行（Executor）和异步计算的结果（Future），底层的机制的大致就是：</p><ol><li><p>主线程首先创建实现任务（Runable/Callable）接口，也就是任务对象。</p></li><li><p>然后把这个任务对象交给ExecutorService执行（具体是ThreadPoolExecutor或者ScheduledThreadPoolExecutor来完成）</p><p>2.1 如果用submit的方式提交，则ExecutorService会会返回一个实现异步计算的结果（Future）接口的对象</p><p>2.2 主线程可以执行FutureTask.get()方法来等待任务执行完成</p></li></ol><p><strong>线程池的一些核心参数有没有配置和使用过？</strong></p><p>核心参数有<strong>3个</strong>：</p><p>​ 核心线程数（corePoolSize）：最小同时运行的线程数量</p><p>​ 最大线程数（maximumPoolSize）：任务达到队列容量之后，最大同时运行的线程数量</p><p>​ 阻塞队列（workQueue）：超过核心线程数的线程存放的队列</p><p>其他参数：线程空闲时的存活时间（keepAliveTime）、时间单位（unit）、线程工程（threadFactory）、拒绝策略（handler）</p><p><strong>核心线程数怎么确定设置多少，设置的依据是什么</strong></p><p>从任务的优先级，任务的执行时间长短，任务的性质（IO密集型/CPU密集型）、任务的依赖关系四个角度分析；比如CPU密集型，尽可能创建少的线程，CPU总核心数+1（+1为了利用等待空闲），IO密集型：尽可能多的线程，CPU总核心数*2+1（eg数据库连接池），当然也可能是混合型，则如果任务执行时间差别较大，就拆分成两个线程池。</p><p>总结：有公式 最佳线程数目 = CPU数目 x（线程等待时间与线程CPU时间之比 + 1）</p><h1 id="java锁" tabindex="-1"><a class="header-anchor" href="#java锁" aria-hidden="true">#</a> Java锁</h1><h2 id="参考-1" tabindex="-1"><a class="header-anchor" href="#参考-1" aria-hidden="true">#</a> 参考</h2>',15),c={href:"https://xiaomi-info.github.io/2020/03/24/synchronized/",target:"_blank",rel:"noopener noreferrer"},g=(0,t.Uk)("Synchronized实现原理"),u=(0,t.Uk)("——小米信息部技术团队"),k={href:"https://www.pdai.tech/md/java/thread/java-thread-x-key-synchronized.html#synchronized%E7%9A%84%E4%BD%BF%E7%94%A8",target:"_blank",rel:"noopener noreferrer"},f=(0,t.Uk)("Synchronized详解"),v=(0,t.Uk)(" ——Java全栈知识体系"),S=(0,t.uE)('<h2 id="面试题-1" tabindex="-1"><a class="header-anchor" href="#面试题-1" aria-hidden="true">#</a> 面试题</h2><p><strong>JUC包中有个Synchronized关键字和ReentrantLock，这两个有什么区别？</strong></p><p>Synchronized关键字是语言层面的内置锁，所有用Synchronized的地方都可以用ReentrantLock来替代，但是ReentrantLock是基于对象层面，也就是代码层面，可以更灵活的使用，设计锁的时候可以基于业务流程来控制这个锁，而Synchronized就只能是修饰方法或者代码块，随着方法或代码块进入会拿到锁，执行完成或者抛异常了就释放锁，其次Synchronized是非公平锁，而ReentrantLock默认是非公平锁，但是可以设置为公平锁，大体上就这些区别。</p><p><strong>那Synchronized底层的一个实现原理是怎样的？</strong></p><p>底层是通过一个monitor监视器对象来实现的，首先Synchronized修饰代码块的时候，通过编译生成的字节码文件，可以看到前后分别有一个monitorenter和monitorexit（这两个最底层是依赖操作系统的MutexLock实现的，该实现需要线程挂起从用户态切换到内核态去完成）也就是当执行到这个monitorenter指令时，monitor这个监视器对象就被占用从而处于锁定状态，具体的过程则是有个锁计数器，初始是0，线程执行到代码块时，计数器+1，一旦+1别的线程在monitorenter时就会失败，从而进入同步队列，等到monitorexit后释放锁之后通知队列，出队列再执行monitorenter获取锁</p><p><strong>那ReentrantLock的实现原理是怎么样的？</strong></p><p>ReentrantLock实现原理相对麻烦一点，它是基于AQS的同步状态state来实现的，当某一线程获取锁后，将state值+1，并记录下当前持有锁的线程，再有线程来获取锁时，会判断这个线程与持有锁的线程是否同一个，如果是则继续+1，不是则阻塞线程，当state减为0时彻底释放锁，并唤醒其他线程，这里也分公平锁和非公平锁，如果是公平锁则为阻塞等待队列的头结点获取锁，如果是非公平锁，则会</p><p><strong>CAS你是如何理解的？</strong></p><p>CAS就是对比交换，是一条CPU的原子指令，作用就是让CPU先进行比较两个值是否相等，然后原子地修改，在实际操作的时候需要两个数值，一个旧值和一个新值，在操作期间先比较下旧值有没有发生变化，没发生变化，则交换成新值，发生了变化则不交换，由于是原子性操作，所以多线程并发使用CAS更新数据时，可以不用锁</p><p><strong>CAS可能存在的问题有哪些？或者说有什么缺点</strong></p><ol><li><strong>ABA问题</strong>，如果值由A变成B又变成A，CAS会认为没有发生变化，实际上已经变化了，解决办法就是使用版本号，在变量前增加版本号，比如1A，2B，3A，或者JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题，检查预期引用和预期标志，全相等会用原子方式更新</li><li>循环时间开销大：CAS自旋长时间不成功，CPU会有很大开销，一直处于一个饥饿的状态，所以此时还是建议用锁</li><li>只能保证一个共享变量的原子操作：可以用锁，或者取巧的办法，合并变量，i = 2，j = a，合并一下ij = 2a，然后用CAS来操作ij；还有AtomicReference类来保证引用对象之间的原子性，支持多个变量放在一个对象中进行CAS操作</li></ol><h1 id="jvm虚拟机" tabindex="-1"><a class="header-anchor" href="#jvm虚拟机" aria-hidden="true">#</a> JVM虚拟机</h1><h2 id="面试题-2" tabindex="-1"><a class="header-anchor" href="#面试题-2" aria-hidden="true">#</a> 面试题</h2><p><strong>Java堆的分代的机制怎么划分的？</strong></p><p>逻辑上分为三块区域（分代原因是优化GC性能）：新生代（Eden和Survivor）、老年代、元空间（1.8前叫永久代），前两者为虚拟机内存，占比为新生代1/3，老年代2/3，元空间则采用直接内存。</p><p>新生代是所有新对象创建的地方， 包含1个Eden和2个Survivor，比例是8:1:1，对应垃圾回收策略为MinorGC，当Eden空间满时触发，采用复制算法，将存活对象复制到其中一个Survivor区，所以每次GC会使用其中1个Survivor区，另一个Survivor区是空的，这就保证内存使用率达到90%，每次复制后分代年龄+1，一般正常经历15次gc仍未回收会复制到老年代；</p><p>老年代主要是存的是经历过新生代依旧存活的对象，以及大对象（需要大量连续内存空间的对象），大对象直接进入老年代的目的是避免在新生代Eden和两个Survivor区之间发生大量的内存拷贝，而在老年代对应的回收策略为MajorGC，可以采用标记清除或标记整理算法，标记清除会存在内存碎片，标记整理则可规避内存碎片。</p><p><strong>怎么判断是不是垃圾可以回收？</strong></p><p>通过GC Roots的根可达性算法，能够到达的对象都是存活的，不可达的对象就可以被回收，GC Roots一般包括：虚拟机栈中引用的对象，本地方法栈中引用的对象，方法区中类静态属性引用的对象，方法区中长亮引用的对象【这几个对象还是有些模糊】</p><p><strong>常用的垃圾回收器有哪些，优缺点？</strong></p><p>一共有7种，3种收集新生代，3种收集老年代，1中贯穿新老年代，除了CMS和G1是可与用户线程并行回收收集，剩下5种(新生代的Serial、ParNew、ParallelScavenge、老年代的Serial Old,Parallel Old)都是串行。</p><p>CMS采用标记-清除算法，优点是可并发标记，因为不需要停顿，可与用户线程一起工作，缺点是吞吐量低，因为低停顿时间是以牺牲吞吐量为代价的，导致CPU利用率不高，其次就是标记-清除算法导致的空间碎片，导致无法给大对象分配内存。</p><p>G1的特点就是跨新生代和老年代回收，G1会把堆划分成多个大小相等的Region，每次回收都是以Region为单位，更灵活，每次回收都会根据回收价值和成本进行排序，维护一个优先级列表，根据用户所期望的GC停顿时间来制定回收计划，优先回收价值最大的Region。整体来看是基于“标记-整理”算法实现，从局部（两个Region之间）来看是基于“复制”算法实现的，也就是不会产生内存碎片。</p><p><strong>MinorGC和FullGC触发的条件？</strong></p><p>MinorGC触发在当Eden区满了就会触发一次（当然前提是老年代内存空间有担保，如果担保失败不会执行，改为执行FullGC）</p><p>FullGC触发条件比较多：</p><p>​ 一是调用System.gc()——只是建议虚拟机执行FullGC，但是虚拟机不一定执行，不建议使用；</p><p>​ 二是老年代空间不足——应尽量避免，因为老年代如果回收后还不足则会OOM</p><p>​ 三是空间分配担保失败——MinorGC的复制算法需要老年代做空间担保，如果担保失败或者设置不担保，则会执行FullGC</p><p><strong>现在线上5台机器出现了OOM异常，你会怎么处理？</strong></p><p>首先OOM出现就是申请不到内存了，那么可能就是有两种情况，一种是内存溢出，经常会有调用外部接口，会进行序列化和反序列化，如果说它是一个列表，反序列化之后列表太长，正好又是并发的时候，频繁反序列化后大对象直接回进入到老年代，最后导致OOM；一种就是内存泄露，一些资源对象没有释放，该关闭的资源没有关闭导致内存泄露引发OOM；如果是第一种的话，需要去监控堆的情况，某一个时间点堆内存占用突然升高，但是过一段时间后就恢复正常了，那就不是内存泄露造成的，而是大对象造成的，如果是内存泄露，会发现这个内存占用率是经过每次gc之后，不断的增高最后导致不够了，像这种只能通过dump出来的文件，通过一些工具来分析，比如阿里的Arthas</p><p><strong>类加载是怎么加载的？什么是双亲委派？</strong></p><h1 id="网络" tabindex="-1"><a class="header-anchor" href="#网络" aria-hidden="true">#</a> 网络</h1><p><strong>谈谈你对Netty的了解？</strong></p><p>Netty是一个基于NIO（非阻塞IO）开发的网络通信框架，相对于BIO（阻塞IO）在并发性能上有很大提高。</p><p><strong>Reactor模型有几种，各有什么特点？</strong></p><p>有三种，分别是单Reactor单线程，单Reactor多线程，主从Reactor多线程</p><p>讲特点前需要了解有三个角色，Reactor（负责监听和分配）、Acceptor（处理客户端连接）、Hander（与事件绑定，执行读/写任务）</p><p>单单：Reactor负责分离套接字，acceptor处理连接，如果不是连接就分发到hander上执行（Redis使用这种）</p><p>单多：Handler只负责响应读/写事件，真正的业务处理由后边的worker线程池处理</p><p>主从多：相对单多，将Reactor分为了mainReactor和subReactor，main和acceptor复制管理连接部分，sub复制分发到hander（Nginx，Netty使用这种）</p><p><strong>谈谈你对BIO、NIO、多路复用、AIO的理解？</strong></p><p>首先这四种都是服务端编程涉及的4种IO模型，在理解这几种IO模型前，需要了解两个缓冲区，一个是内核缓冲区，一个是用户缓冲区，实际上在服务端接受客户端请求时，建立连接后还需要等待数据，用户程序空间和Linux内核空间会进行read和write的系统调用，数据实际上是先通过网卡到内核缓冲区，等待缓冲区达到一定数量后服务器从内核缓冲区读数据到用户缓冲区，处理之后再写到内核，通过网卡发送到客户端。</p><p>所以BIO也就是阻塞IO，也就是内核IO操作彻底完成后，才返回用户空间，所以用户从read调用到调用返回是阻塞的，因为要等待内核缓冲区准备数据，然后再复制到用户缓冲区。当新的请求过来，就需要创建新的线程来处理，将造成大量的线程创建和销毁。</p><p>NIO实际上就是非阻塞IO，通过将所有的线程的维护到一个列表里，每次去轮询列表是否有数据就绪，有就用当前处理，CPU一直循环当前列表，同时判断是否有新的请求建立，有就添加到列表里，并且将IO请求都设置成非阻塞，在线程发起read系统调用后，内核立马返回一个状态值，不需要等待内核缓冲区和复制迩阻塞，但是要不断的轮循，所以线程列表过大，这就可能造成毫无意义的轮循，也一定程度占用了CPU资源。</p><p>IO多路复用则是经典的Reactor设计模式，也就是异步阻塞IO，在NIO的基础上，也就是循环遍历列表的事情有内核态的系统函数去调用，将所有的连接请求封装成文件描述符给到系统函数，系统函数监听这些文件描述符描述的文件，一旦有文件描述符对应的内容发生了变更，则通知select/epoll去调用，向用户进程缓冲区复制数据，过程中用户线程并不需要去阻塞，也不用一直占用CPU资源去轮询列表，也不会在读取数据时阻塞，最好的解决了上述问题，它是比如Java中的selector和Linux的epoll都是这种模型。</p><p>AIO也是异步IO，指的是用户空间和内核空间调用方式反过来，类似Java中的回调模式，用户线程向内核注册各种IO事件的回调参数，由内核去主动调用</p><p>总结：造成这几种不同的模型，根本上也是因为数据是需要经过内核接收数据包完成由准备到复制到用户空间的一个过程，所以这个间隙就体现出不同的区别了。四种IO模型，理论上越往后，阻塞越小，效率也是最优。</p><h1 id="redis" tabindex="-1"><a class="header-anchor" href="#redis" aria-hidden="true">#</a> Redis</h1><p><strong>redis的简单框架</strong></p><p>访问框架（动态库、网络访问框架）、操作模块（PUT/GET/SACN/DELETE）、索引模块、存储模块（持久化）</p><p><strong>两大维度</strong></p><p>应用维度（数据结构应用、缓存应用、集群应用）、系统维度</p><h2 id="数据结构" tabindex="-1"><a class="header-anchor" href="#数据结构" aria-hidden="true">#</a> <strong>数据结构</strong></h2><ul><li></li></ul><h2 id="面试题-3" tabindex="-1"><a class="header-anchor" href="#面试题-3" aria-hidden="true">#</a> 面试题</h2>',56),m={href:"https://cloud.tencent.com/developer/article/1710467",target:"_blank",rel:"noopener noreferrer"},b=(0,t.Uk)("面试官最爱问的 11道 Redis 面试题"),C=(0,t.Uk)("——程序员内点事"),O={href:"https://mp.weixin.qq.com/s/TvTiJlwJa2hN6BnE31vsuA",target:"_blank",rel:"noopener noreferrer"},x=(0,t.Uk)("20道Redis经典面试题打包带走"),A=(0,t.Uk)("——黎杜编程"),R=(0,t.uE)('<p><strong>说说redis基本数据类型有哪些吧</strong></p><p>Tips：5种基础数据类型，共7种基础数据结构，注意回答每种基础数据结构的特点，为什么redis这么设计来使用？</p><ol><li><p>字符串：【String】简单动态字符串SDS，记录了字符长度和未使用长度，获取字符串长度的时间复杂度从C语言char[]的O(n)降低到O(1)；应用场景有共享session，分布式锁，计数器，限流，防止频繁操作</p></li><li><p>压缩列表：【List①】【Hash①】【ZSet①】有多个节点，每个节点都存储了前一个元素的长度，目的是为了节省空间</p></li><li><p>链表：【List②】采用无环的双向链表，除了头结点都有两个指向前和后的指针，很多发布订阅、慢查询、监视器都使用</p></li><li><p>字典hashtable：【Hash②】【Set①】键值对数据结构，每个都有两个hash表，一个平时使用，一个rehash使用，产生哈希碰撞会形成单链表，为了服务可用性，rehash是渐进式的</p></li><li><p>跳表：【ZSet②】由表头，跳跃表节点，层数，表尾组成，redis中的有序集合键、集群节点的内部结构中都是用到了跳跃表</p></li><li><p>整数集合intset：【Set②】底层实现是数组，不会有重复元素</p></li></ol><p>基础类型：String(动态字符串SDS)、List(压缩列表、链表)、Hash（压缩列表、哈希表）、ZSet(压缩列表、跳表)、Set(整数数组、哈希表)</p><p><strong>Redis为什么快？</strong></p><p>从几个方面，首先是基于内存的，其次有高效的数据结构（动态字符串，压缩列表、渐进式rehash、跳表）、合理的线程模型，采用单线程避免上下文切换，同时又采用多路复用的IO网络操作模型</p><p><strong>热key的问题如何解决？</strong></p><p>热key就是高频访问的key，如果并发时，高流量的请求访问同一个key会达到物理网卡上限，导致可能宕机引发雪崩</p><p>解决方案：将热key打散到不同服务器，或者加入二级缓存，提前加载到内存，宕机后走内存查询</p><p><strong>缓存击穿、穿透、雪崩是什么，如何解决？</strong></p><p>击穿：高并发访问同一个key时，key超时过期导致直接访问数据库（加锁更新，请求查询A，没有则对A加锁，然后从数据库查询回来放入缓存；将过期时间组合写入value中，异步不断刷新过期时间）</p><p>穿透：访问不存在的key，导致大量请求打到数据库上（考虑加一层布隆过滤器，原理就是会通过散列函数映射到个位数组中的k个点，置为1，只要请求来访问，而布隆过滤器上是0，则会直接返回）</p><p>雪崩：某一时刻，大量key失效导致直接打到数据库上（给不同key设置不同的超时时间；redis宕机后限流；加入二级缓存类似热key）</p><p><strong>Redis的过期策略有哪些？</strong></p><p>惰性删除，查询key的时候发现超时才删除；定期删除：每隔一段时间，删除过期的key，但是是随机抽查部分，并不是所有；如果上面两种都没有删除掉，则会走redis的内存淘汰机制：有淘汰最近最少使用的，即将过期的，随机删除等</p><h1 id="数据库" tabindex="-1"><a class="header-anchor" href="#数据库" aria-hidden="true">#</a> 数据库</h1><h2 id="面试题-4" tabindex="-1"><a class="header-anchor" href="#面试题-4" aria-hidden="true">#</a> 面试题</h2>',17),y={href:"https://mp.weixin.qq.com/s?__biz=MzU1MzE4OTU0OQ==&mid=2247487126&idx=1&sn=dd36423f6726852bc18eeef0d7c4e4da&chksm=fbf7e754cc806e421d90fa47bcd9666f112979dd4106d237be0da8f92f9400e09bd773c937f0&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},U=(0,t.Uk)("精心为你准备的最全的20道MySQL面试题"),_=(0,t.uE)('<p><strong>谈谈你对事务是如何理解的</strong>？</p><p>在数据库中的事务，比如我们平时实现一个业务，可能涉及执行多条SQL，那么事务就是在这整个个过程中，确保要么全部成功，要么全部执行失败，这个也就是事务ACID的四个特性中之一的原子性，除了这个特点之外呢，还有事务之间都是隔离的，不受影响，这样也保证了每个事务在整个过程中前后状态的一致性，最后在这一些列操作执行结束后，事务一旦提交，这个过程对数据的改变就是持久性的，总结起来就是，为了完成一系列操作，不管是查询还是修改，最终的目的是整体的一致性。包括原子性、隔离性，持久化都是保障一致性而存在的。</p><p><strong>事务都有哪些特性</strong>？</p><p>ACID：原子性(全成功全失败)，一致性(前后数据一致性)，隔离性(相互隔离不影响)，持久化(一旦提交数据的改变是持久化的)</p><p><strong>隔离级别呢？分别解决了什么问题？</strong></p><h1 id="分布式事务" tabindex="-1"><a class="header-anchor" href="#分布式事务" aria-hidden="true">#</a> 分布式事务</h1><h2 id="面试题-5" tabindex="-1"><a class="header-anchor" href="#面试题-5" aria-hidden="true">#</a> 面试题</h2><p><strong>两阶段提交，你怎么理解的？</strong></p><p>prepare和commit......待补充</p><p><strong>还有一个三阶段跟两阶段提交有什么不同</strong></p><p>两阶段存在阻塞问题</p><p><strong>阿里的分布式框架Seata，有了解吗？</strong></p><p>暂时没有，我们一般做分布式事务就是两种，一种是基于Saga这种消息驱动，准备两个事务，一个是业务逻辑消息，一个是回滚消息，当上游业务失败回滚后，也要做对应的事务回滚，就准备这两种consumer；另一种是基于RocketMQ的事务消息，相当于是一个二阶段提交</p>',13),I={render:function(e,r){const a=(0,t.up)("OutboundLink");return(0,t.wg)(),(0,t.iD)(t.HY,null,[n,(0,t._)("p",null,[(0,t._)("a",i,[p,(0,t.Wm)(a)]),o]),(0,t._)("p",null,[(0,t._)("a",l,[s,(0,t.Wm)(a)]),d]),h,(0,t._)("p",null,[(0,t._)("a",c,[g,(0,t.Wm)(a)]),u]),(0,t._)("p",null,[(0,t._)("a",k,[f,(0,t.Wm)(a)]),v]),S,(0,t._)("p",null,[(0,t._)("a",m,[b,(0,t.Wm)(a)]),C]),(0,t._)("p",null,[(0,t._)("a",O,[x,(0,t.Wm)(a)]),A]),R,(0,t._)("p",null,[(0,t._)("a",y,[U,(0,t.Wm)(a)])]),_],64)}}}}]);